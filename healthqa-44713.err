`torch_dtype` is deprecated! Use `dtype` instead!
TinyLlama/TinyLlama-1.1B-Chat-v1.0:   0%|          | 0/20 [00:00<?, ?it/s]TinyLlama/TinyLlama-1.1B-Chat-v1.0:   5%|▌         | 1/20 [00:05<01:51,  5.86s/it]TinyLlama/TinyLlama-1.1B-Chat-v1.0:  10%|█         | 2/20 [00:11<01:39,  5.55s/it]TinyLlama/TinyLlama-1.1B-Chat-v1.0:  15%|█▌        | 3/20 [00:16<01:32,  5.46s/it]TinyLlama/TinyLlama-1.1B-Chat-v1.0:  20%|██        | 4/20 [00:21<01:26,  5.41s/it]TinyLlama/TinyLlama-1.1B-Chat-v1.0:  25%|██▌       | 5/20 [00:27<01:20,  5.38s/it]TinyLlama/TinyLlama-1.1B-Chat-v1.0:  30%|███       | 6/20 [00:32<01:15,  5.37s/it]TinyLlama/TinyLlama-1.1B-Chat-v1.0:  35%|███▌      | 7/20 [00:37<01:09,  5.35s/it]TinyLlama/TinyLlama-1.1B-Chat-v1.0:  40%|████      | 8/20 [00:38<00:47,  3.98s/it]TinyLlama/TinyLlama-1.1B-Chat-v1.0:  45%|████▌     | 9/20 [00:44<00:48,  4.40s/it]TinyLlama/TinyLlama-1.1B-Chat-v1.0:  50%|█████     | 10/20 [00:49<00:46,  4.69s/it]TinyLlama/TinyLlama-1.1B-Chat-v1.0:  55%|█████▌    | 11/20 [00:54<00:43,  4.88s/it]TinyLlama/TinyLlama-1.1B-Chat-v1.0:  60%|██████    | 12/20 [01:00<00:40,  5.02s/it]TinyLlama/TinyLlama-1.1B-Chat-v1.0:  65%|██████▌   | 13/20 [01:02<00:28,  4.14s/it]TinyLlama/TinyLlama-1.1B-Chat-v1.0:  70%|███████   | 14/20 [01:07<00:27,  4.50s/it]TinyLlama/TinyLlama-1.1B-Chat-v1.0:  75%|███████▌  | 15/20 [01:13<00:23,  4.75s/it]TinyLlama/TinyLlama-1.1B-Chat-v1.0:  80%|████████  | 16/20 [01:18<00:19,  4.92s/it]TinyLlama/TinyLlama-1.1B-Chat-v1.0:  85%|████████▌ | 17/20 [01:23<00:15,  5.04s/it]TinyLlama/TinyLlama-1.1B-Chat-v1.0:  90%|█████████ | 18/20 [01:28<00:10,  5.13s/it]TinyLlama/TinyLlama-1.1B-Chat-v1.0:  95%|█████████▌| 19/20 [01:34<00:05,  5.19s/it]TinyLlama/TinyLlama-1.1B-Chat-v1.0: 100%|██████████| 20/20 [01:39<00:00,  5.23s/it]TinyLlama/TinyLlama-1.1B-Chat-v1.0: 100%|██████████| 20/20 [01:39<00:00,  4.98s/it]
judge:   0%|          | 0/20 [00:00<?, ?it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.
The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
judge:   5%|▌         | 1/20 [00:12<04:05, 12.92s/it]judge:  10%|█         | 2/20 [00:25<03:52, 12.89s/it]judge:  15%|█▌        | 3/20 [00:38<03:39, 12.89s/it]judge:  20%|██        | 4/20 [00:51<03:26, 12.89s/it]judge:  25%|██▌       | 5/20 [01:04<03:13, 12.88s/it]judge:  30%|███       | 6/20 [01:17<03:00, 12.87s/it]judge:  35%|███▌      | 7/20 [01:30<02:47, 12.86s/it]judge:  40%|████      | 8/20 [01:42<02:34, 12.85s/it]judge:  45%|████▌     | 9/20 [01:55<02:21, 12.86s/it]judge:  50%|█████     | 10/20 [02:08<02:08, 12.86s/it]judge:  55%|█████▌    | 11/20 [02:21<01:55, 12.87s/it]judge:  60%|██████    | 12/20 [02:34<01:42, 12.87s/it]judge:  65%|██████▌   | 13/20 [02:47<01:30, 12.87s/it]judge:  70%|███████   | 14/20 [03:00<01:17, 12.86s/it]judge:  75%|███████▌  | 15/20 [03:13<01:04, 12.87s/it]judge:  80%|████████  | 16/20 [03:25<00:51, 12.87s/it]judge:  85%|████████▌ | 17/20 [03:38<00:38, 12.89s/it]judge:  90%|█████████ | 18/20 [03:52<00:26, 13.24s/it]judge:  95%|█████████▌| 19/20 [04:05<00:13, 13.13s/it]judge: 100%|██████████| 20/20 [04:18<00:00, 13.05s/it]judge: 100%|██████████| 20/20 [04:18<00:00, 12.93s/it]
`torch_dtype` is deprecated! Use `dtype` instead!
/mnt/vstor/courses/csds447/kvl16/project/csds447-health-qa-safety/venv/lib/python3.12/site-packages/peft/peft_model.py:598: UserWarning: Found missing adapter keys while loading the checkpoint: ['base_model.model.biogpt.layers.0.self_attn.v_proj.lora_A.default.weight', 'base_model.model.biogpt.layers.0.self_attn.v_proj.lora_B.default.weight', 'base_model.model.biogpt.layers.0.self_attn.q_proj.lora_A.default.weight', 'base_model.model.biogpt.layers.0.self_attn.q_proj.lora_B.default.weight', 'base_model.model.biogpt.layers.1.self_attn.v_proj.lora_A.default.weight', 'base_model.model.biogpt.layers.1.self_attn.v_proj.lora_B.default.weight', 'base_model.model.biogpt.layers.1.self_attn.q_proj.lora_A.default.weight', 'base_model.model.biogpt.layers.1.self_attn.q_proj.lora_B.default.weight', 'base_model.model.biogpt.layers.2.self_attn.v_proj.lora_A.default.weight', 'base_model.model.biogpt.layers.2.self_attn.v_proj.lora_B.default.weight', 'base_model.model.biogpt.layers.2.self_attn.q_proj.lora_A.default.weight', 'base_model.model.biogpt.layers.2.self_attn.q_proj.lora_B.default.weight', 'base_model.model.biogpt.layers.3.self_attn.v_proj.lora_A.default.weight', 'base_model.model.biogpt.layers.3.self_attn.v_proj.lora_B.default.weight', 'base_model.model.biogpt.layers.3.self_attn.q_proj.lora_A.default.weight', 'base_model.model.biogpt.layers.3.self_attn.q_proj.lora_B.default.weight', 'base_model.model.biogpt.layers.4.self_attn.v_proj.lora_A.default.weight', 'base_model.model.biogpt.layers.4.self_attn.v_proj.lora_B.default.weight', 'base_model.model.biogpt.layers.4.self_attn.q_proj.lora_A.default.weight', 'base_model.model.biogpt.layers.4.self_attn.q_proj.lora_B.default.weight', 'base_model.model.biogpt.layers.5.self_attn.v_proj.lora_A.default.weight', 'base_model.model.biogpt.layers.5.self_attn.v_proj.lora_B.default.weight', 'base_model.model.biogpt.layers.5.self_attn.q_proj.lora_A.default.weight', 'base_model.model.biogpt.layers.5.self_attn.q_proj.lora_B.default.weight', 'base_model.model.biogpt.layers.6.self_attn.v_proj.lora_A.default.weight', 'base_model.model.biogpt.layers.6.self_attn.v_proj.lora_B.default.weight', 'base_model.model.biogpt.layers.6.self_attn.q_proj.lora_A.default.weight', 'base_model.model.biogpt.layers.6.self_attn.q_proj.lora_B.default.weight', 'base_model.model.biogpt.layers.7.self_attn.v_proj.lora_A.default.weight', 'base_model.model.biogpt.layers.7.self_attn.v_proj.lora_B.default.weight', 'base_model.model.biogpt.layers.7.self_attn.q_proj.lora_A.default.weight', 'base_model.model.biogpt.layers.7.self_attn.q_proj.lora_B.default.weight', 'base_model.model.biogpt.layers.8.self_attn.v_proj.lora_A.default.weight', 'base_model.model.biogpt.layers.8.self_attn.v_proj.lora_B.default.weight', 'base_model.model.biogpt.layers.8.self_attn.q_proj.lora_A.default.weight', 'base_model.model.biogpt.layers.8.self_attn.q_proj.lora_B.default.weight', 'base_model.model.biogpt.layers.9.self_attn.v_proj.lora_A.default.weight', 'base_model.model.biogpt.layers.9.self_attn.v_proj.lora_B.default.weight', 'base_model.model.biogpt.layers.9.self_attn.q_proj.lora_A.default.weight', 'base_model.model.biogpt.layers.9.self_attn.q_proj.lora_B.default.weight', 'base_model.model.biogpt.layers.10.self_attn.v_proj.lora_A.default.weight', 'base_model.model.biogpt.layers.10.self_attn.v_proj.lora_B.default.weight', 'base_model.model.biogpt.layers.10.self_attn.q_proj.lora_A.default.weight', 'base_model.model.biogpt.layers.10.self_attn.q_proj.lora_B.default.weight', 'base_model.model.biogpt.layers.11.self_attn.v_proj.lora_A.default.weight', 'base_model.model.biogpt.layers.11.self_attn.v_proj.lora_B.default.weight', 'base_model.model.biogpt.layers.11.self_attn.q_proj.lora_A.default.weight', 'base_model.model.biogpt.layers.11.self_attn.q_proj.lora_B.default.weight', 'base_model.model.biogpt.layers.12.self_attn.v_proj.lora_A.default.weight', 'base_model.model.biogpt.layers.12.self_attn.v_proj.lora_B.default.weight', 'base_model.model.biogpt.layers.12.self_attn.q_proj.lora_A.default.weight', 'base_model.model.biogpt.layers.12.self_attn.q_proj.lora_B.default.weight', 'base_model.model.biogpt.layers.13.self_attn.v_proj.lora_A.default.weight', 'base_model.model.biogpt.layers.13.self_attn.v_proj.lora_B.default.weight', 'base_model.model.biogpt.layers.13.self_attn.q_proj.lora_A.default.weight', 'base_model.model.biogpt.layers.13.self_attn.q_proj.lora_B.default.weight', 'base_model.model.biogpt.layers.14.self_attn.v_proj.lora_A.default.weight', 'base_model.model.biogpt.layers.14.self_attn.v_proj.lora_B.default.weight', 'base_model.model.biogpt.layers.14.self_attn.q_proj.lora_A.default.weight', 'base_model.model.biogpt.layers.14.self_attn.q_proj.lora_B.default.weight', 'base_model.model.biogpt.layers.15.self_attn.v_proj.lora_A.default.weight', 'base_model.model.biogpt.layers.15.self_attn.v_proj.lora_B.default.weight', 'base_model.model.biogpt.layers.15.self_attn.q_proj.lora_A.default.weight', 'base_model.model.biogpt.layers.15.self_attn.q_proj.lora_B.default.weight', 'base_model.model.biogpt.layers.16.self_attn.v_proj.lora_A.default.weight', 'base_model.model.biogpt.layers.16.self_attn.v_proj.lora_B.default.weight', 'base_model.model.biogpt.layers.16.self_attn.q_proj.lora_A.default.weight', 'base_model.model.biogpt.layers.16.self_attn.q_proj.lora_B.default.weight', 'base_model.model.biogpt.layers.17.self_attn.v_proj.lora_A.default.weight', 'base_model.model.biogpt.layers.17.self_attn.v_proj.lora_B.default.weight', 'base_model.model.biogpt.layers.17.self_attn.q_proj.lora_A.default.weight', 'base_model.model.biogpt.layers.17.self_attn.q_proj.lora_B.default.weight', 'base_model.model.biogpt.layers.18.self_attn.v_proj.lora_A.default.weight', 'base_model.model.biogpt.layers.18.self_attn.v_proj.lora_B.default.weight', 'base_model.model.biogpt.layers.18.self_attn.q_proj.lora_A.default.weight', 'base_model.model.biogpt.layers.18.self_attn.q_proj.lora_B.default.weight', 'base_model.model.biogpt.layers.19.self_attn.v_proj.lora_A.default.weight', 'base_model.model.biogpt.layers.19.self_attn.v_proj.lora_B.default.weight', 'base_model.model.biogpt.layers.19.self_attn.q_proj.lora_A.default.weight', 'base_model.model.biogpt.layers.19.self_attn.q_proj.lora_B.default.weight', 'base_model.model.biogpt.layers.20.self_attn.v_proj.lora_A.default.weight', 'base_model.model.biogpt.layers.20.self_attn.v_proj.lora_B.default.weight', 'base_model.model.biogpt.layers.20.self_attn.q_proj.lora_A.default.weight', 'base_model.model.biogpt.layers.20.self_attn.q_proj.lora_B.default.weight', 'base_model.model.biogpt.layers.21.self_attn.v_proj.lora_A.default.weight', 'base_model.model.biogpt.layers.21.self_attn.v_proj.lora_B.default.weight', 'base_model.model.biogpt.layers.21.self_attn.q_proj.lora_A.default.weight', 'base_model.model.biogpt.layers.21.self_attn.q_proj.lora_B.default.weight', 'base_model.model.biogpt.layers.22.self_attn.v_proj.lora_A.default.weight', 'base_model.model.biogpt.layers.22.self_attn.v_proj.lora_B.default.weight', 'base_model.model.biogpt.layers.22.self_attn.q_proj.lora_A.default.weight', 'base_model.model.biogpt.layers.22.self_attn.q_proj.lora_B.default.weight', 'base_model.model.biogpt.layers.23.self_attn.v_proj.lora_A.default.weight', 'base_model.model.biogpt.layers.23.self_attn.v_proj.lora_B.default.weight', 'base_model.model.biogpt.layers.23.self_attn.q_proj.lora_A.default.weight', 'base_model.model.biogpt.layers.23.self_attn.q_proj.lora_B.default.weight', 'base_model.model.biogpt.layers.24.self_attn.v_proj.lora_A.default.weight', 'base_model.model.biogpt.layers.24.self_attn.v_proj.lora_B.default.weight', 'base_model.model.biogpt.layers.24.self_attn.q_proj.lora_A.default.weight', 'base_model.model.biogpt.layers.24.self_attn.q_proj.lora_B.default.weight', 'base_model.model.biogpt.layers.25.self_attn.v_proj.lora_A.default.weight', 'base_model.model.biogpt.layers.25.self_attn.v_proj.lora_B.default.weight', 'base_model.model.biogpt.layers.25.self_attn.q_proj.lora_A.default.weight', 'base_model.model.biogpt.layers.25.self_attn.q_proj.lora_B.default.weight', 'base_model.model.biogpt.layers.26.self_attn.v_proj.lora_A.default.weight', 'base_model.model.biogpt.layers.26.self_attn.v_proj.lora_B.default.weight', 'base_model.model.biogpt.layers.26.self_attn.q_proj.lora_A.default.weight', 'base_model.model.biogpt.layers.26.self_attn.q_proj.lora_B.default.weight', 'base_model.model.biogpt.layers.27.self_attn.v_proj.lora_A.default.weight', 'base_model.model.biogpt.layers.27.self_attn.v_proj.lora_B.default.weight', 'base_model.model.biogpt.layers.27.self_attn.q_proj.lora_A.default.weight', 'base_model.model.biogpt.layers.27.self_attn.q_proj.lora_B.default.weight', 'base_model.model.biogpt.layers.28.self_attn.v_proj.lora_A.default.weight', 'base_model.model.biogpt.layers.28.self_attn.v_proj.lora_B.default.weight', 'base_model.model.biogpt.layers.28.self_attn.q_proj.lora_A.default.weight', 'base_model.model.biogpt.layers.28.self_attn.q_proj.lora_B.default.weight', 'base_model.model.biogpt.layers.29.self_attn.v_proj.lora_A.default.weight', 'base_model.model.biogpt.layers.29.self_attn.v_proj.lora_B.default.weight', 'base_model.model.biogpt.layers.29.self_attn.q_proj.lora_A.default.weight', 'base_model.model.biogpt.layers.29.self_attn.q_proj.lora_B.default.weight', 'base_model.model.biogpt.layers.30.self_attn.v_proj.lora_A.default.weight', 'base_model.model.biogpt.layers.30.self_attn.v_proj.lora_B.default.weight', 'base_model.model.biogpt.layers.30.self_attn.q_proj.lora_A.default.weight', 'base_model.model.biogpt.layers.30.self_attn.q_proj.lora_B.default.weight', 'base_model.model.biogpt.layers.31.self_attn.v_proj.lora_A.default.weight', 'base_model.model.biogpt.layers.31.self_attn.v_proj.lora_B.default.weight', 'base_model.model.biogpt.layers.31.self_attn.q_proj.lora_A.default.weight', 'base_model.model.biogpt.layers.31.self_attn.q_proj.lora_B.default.weight', 'base_model.model.biogpt.layers.32.self_attn.v_proj.lora_A.default.weight', 'base_model.model.biogpt.layers.32.self_attn.v_proj.lora_B.default.weight', 'base_model.model.biogpt.layers.32.self_attn.q_proj.lora_A.default.weight', 'base_model.model.biogpt.layers.32.self_attn.q_proj.lora_B.default.weight', 'base_model.model.biogpt.layers.33.self_attn.v_proj.lora_A.default.weight', 'base_model.model.biogpt.layers.33.self_attn.v_proj.lora_B.default.weight', 'base_model.model.biogpt.layers.33.self_attn.q_proj.lora_A.default.weight', 'base_model.model.biogpt.layers.33.self_attn.q_proj.lora_B.default.weight', 'base_model.model.biogpt.layers.34.self_attn.v_proj.lora_A.default.weight', 'base_model.model.biogpt.layers.34.self_attn.v_proj.lora_B.default.weight', 'base_model.model.biogpt.layers.34.self_attn.q_proj.lora_A.default.weight', 'base_model.model.biogpt.layers.34.self_attn.q_proj.lora_B.default.weight', 'base_model.model.biogpt.layers.35.self_attn.v_proj.lora_A.default.weight', 'base_model.model.biogpt.layers.35.self_attn.v_proj.lora_B.default.weight', 'base_model.model.biogpt.layers.35.self_attn.q_proj.lora_A.default.weight', 'base_model.model.biogpt.layers.35.self_attn.q_proj.lora_B.default.weight', 'base_model.model.biogpt.layers.36.self_attn.v_proj.lora_A.default.weight', 'base_model.model.biogpt.layers.36.self_attn.v_proj.lora_B.default.weight', 'base_model.model.biogpt.layers.36.self_attn.q_proj.lora_A.default.weight', 'base_model.model.biogpt.layers.36.self_attn.q_proj.lora_B.default.weight', 'base_model.model.biogpt.layers.37.self_attn.v_proj.lora_A.default.weight', 'base_model.model.biogpt.layers.37.self_attn.v_proj.lora_B.default.weight', 'base_model.model.biogpt.layers.37.self_attn.q_proj.lora_A.default.weight', 'base_model.model.biogpt.layers.37.self_attn.q_proj.lora_B.default.weight', 'base_model.model.biogpt.layers.38.self_attn.v_proj.lora_A.default.weight', 'base_model.model.biogpt.layers.38.self_attn.v_proj.lora_B.default.weight', 'base_model.model.biogpt.layers.38.self_attn.q_proj.lora_A.default.weight', 'base_model.model.biogpt.layers.38.self_attn.q_proj.lora_B.default.weight', 'base_model.model.biogpt.layers.39.self_attn.v_proj.lora_A.default.weight', 'base_model.model.biogpt.layers.39.self_attn.v_proj.lora_B.default.weight', 'base_model.model.biogpt.layers.39.self_attn.q_proj.lora_A.default.weight', 'base_model.model.biogpt.layers.39.self_attn.q_proj.lora_B.default.weight', 'base_model.model.biogpt.layers.40.self_attn.v_proj.lora_A.default.weight', 'base_model.model.biogpt.layers.40.self_attn.v_proj.lora_B.default.weight', 'base_model.model.biogpt.layers.40.self_attn.q_proj.lora_A.default.weight', 'base_model.model.biogpt.layers.40.self_attn.q_proj.lora_B.default.weight', 'base_model.model.biogpt.layers.41.self_attn.v_proj.lora_A.default.weight', 'base_model.model.biogpt.layers.41.self_attn.v_proj.lora_B.default.weight', 'base_model.model.biogpt.layers.41.self_attn.q_proj.lora_A.default.weight', 'base_model.model.biogpt.layers.41.self_attn.q_proj.lora_B.default.weight', 'base_model.model.biogpt.layers.42.self_attn.v_proj.lora_A.default.weight', 'base_model.model.biogpt.layers.42.self_attn.v_proj.lora_B.default.weight', 'base_model.model.biogpt.layers.42.self_attn.q_proj.lora_A.default.weight', 'base_model.model.biogpt.layers.42.self_attn.q_proj.lora_B.default.weight', 'base_model.model.biogpt.layers.43.self_attn.v_proj.lora_A.default.weight', 'base_model.model.biogpt.layers.43.self_attn.v_proj.lora_B.default.weight', 'base_model.model.biogpt.layers.43.self_attn.q_proj.lora_A.default.weight', 'base_model.model.biogpt.layers.43.self_attn.q_proj.lora_B.default.weight', 'base_model.model.biogpt.layers.44.self_attn.v_proj.lora_A.default.weight', 'base_model.model.biogpt.layers.44.self_attn.v_proj.lora_B.default.weight', 'base_model.model.biogpt.layers.44.self_attn.q_proj.lora_A.default.weight', 'base_model.model.biogpt.layers.44.self_attn.q_proj.lora_B.default.weight', 'base_model.model.biogpt.layers.45.self_attn.v_proj.lora_A.default.weight', 'base_model.model.biogpt.layers.45.self_attn.v_proj.lora_B.default.weight', 'base_model.model.biogpt.layers.45.self_attn.q_proj.lora_A.default.weight', 'base_model.model.biogpt.layers.45.self_attn.q_proj.lora_B.default.weight', 'base_model.model.biogpt.layers.46.self_attn.v_proj.lora_A.default.weight', 'base_model.model.biogpt.layers.46.self_attn.v_proj.lora_B.default.weight', 'base_model.model.biogpt.layers.46.self_attn.q_proj.lora_A.default.weight', 'base_model.model.biogpt.layers.46.self_attn.q_proj.lora_B.default.weight', 'base_model.model.biogpt.layers.47.self_attn.v_proj.lora_A.default.weight', 'base_model.model.biogpt.layers.47.self_attn.v_proj.lora_B.default.weight', 'base_model.model.biogpt.layers.47.self_attn.q_proj.lora_A.default.weight', 'base_model.model.biogpt.layers.47.self_attn.q_proj.lora_B.default.weight'].
  warnings.warn(warn_message)
microsoft/BioGPT-Large:   0%|          | 0/20 [00:00<?, ?it/s]microsoft/BioGPT-Large:   5%|▌         | 1/20 [00:01<00:35,  1.89s/it]microsoft/BioGPT-Large:  10%|█         | 2/20 [00:02<00:22,  1.27s/it]microsoft/BioGPT-Large:  15%|█▌        | 3/20 [00:10<01:10,  4.16s/it]microsoft/BioGPT-Large:  20%|██        | 4/20 [00:11<00:45,  2.83s/it]microsoft/BioGPT-Large:  25%|██▌       | 5/20 [00:11<00:31,  2.07s/it]microsoft/BioGPT-Large:  30%|███       | 6/20 [00:18<00:52,  3.77s/it]microsoft/BioGPT-Large:  35%|███▌      | 7/20 [00:19<00:36,  2.79s/it]microsoft/BioGPT-Large:  40%|████      | 8/20 [00:20<00:25,  2.15s/it]microsoft/BioGPT-Large:  45%|████▌     | 9/20 [00:21<00:18,  1.68s/it]microsoft/BioGPT-Large:  50%|█████     | 10/20 [00:28<00:33,  3.33s/it]microsoft/BioGPT-Large:  55%|█████▌    | 11/20 [00:35<00:40,  4.49s/it]microsoft/BioGPT-Large:  60%|██████    | 12/20 [00:41<00:41,  5.15s/it]microsoft/BioGPT-Large:  65%|██████▌   | 13/20 [00:42<00:26,  3.81s/it]microsoft/BioGPT-Large:  70%|███████   | 14/20 [00:49<00:28,  4.68s/it]microsoft/BioGPT-Large:  75%|███████▌  | 15/20 [00:50<00:18,  3.71s/it]microsoft/BioGPT-Large:  80%|████████  | 16/20 [00:51<00:11,  2.82s/it]microsoft/BioGPT-Large:  85%|████████▌ | 17/20 [00:58<00:11,  3.98s/it]microsoft/BioGPT-Large:  90%|█████████ | 18/20 [01:04<00:09,  4.78s/it]microsoft/BioGPT-Large:  95%|█████████▌| 19/20 [01:05<00:03,  3.54s/it]microsoft/BioGPT-Large: 100%|██████████| 20/20 [01:06<00:00,  2.70s/it]microsoft/BioGPT-Large: 100%|██████████| 20/20 [01:06<00:00,  3.31s/it]
judge:   0%|          | 0/20 [00:00<?, ?it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.
The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
judge:   5%|▌         | 1/20 [00:12<03:59, 12.60s/it]judge:  10%|█         | 2/20 [00:25<03:45, 12.54s/it]judge:  15%|█▌        | 3/20 [00:37<03:33, 12.54s/it]judge:  20%|██        | 4/20 [00:50<03:20, 12.52s/it]judge:  25%|██▌       | 5/20 [01:02<03:07, 12.51s/it]judge:  30%|███       | 6/20 [01:15<02:55, 12.51s/it]judge:  35%|███▌      | 7/20 [01:27<02:42, 12.51s/it]judge:  40%|████      | 8/20 [01:40<02:30, 12.51s/it]judge:  45%|████▌     | 9/20 [01:52<02:17, 12.50s/it]judge:  50%|█████     | 10/20 [02:05<02:05, 12.50s/it]judge:  55%|█████▌    | 11/20 [02:17<01:52, 12.50s/it]judge:  60%|██████    | 12/20 [02:30<01:40, 12.50s/it]judge:  65%|██████▌   | 13/20 [02:42<01:27, 12.51s/it]judge:  70%|███████   | 14/20 [02:55<01:15, 12.51s/it]judge:  75%|███████▌  | 15/20 [03:08<01:03, 12.63s/it]judge:  80%|████████  | 16/20 [03:21<00:51, 12.83s/it]judge:  85%|████████▌ | 17/20 [03:34<00:38, 12.96s/it]judge:  90%|█████████ | 18/20 [03:47<00:25, 12.90s/it]judge:  95%|█████████▌| 19/20 [04:00<00:12, 12.83s/it]judge: 100%|██████████| 20/20 [04:12<00:00, 12.76s/it]judge: 100%|██████████| 20/20 [04:12<00:00, 12.63s/it]
`torch_dtype` is deprecated! Use `dtype` instead!
TinyLlama/TinyLlama-1.1B-Chat-v1.0:   0%|          | 0/20 [00:00<?, ?it/s]TinyLlama/TinyLlama-1.1B-Chat-v1.0:   5%|▌         | 1/20 [00:05<01:49,  5.77s/it]TinyLlama/TinyLlama-1.1B-Chat-v1.0:  10%|█         | 2/20 [00:11<01:41,  5.65s/it]TinyLlama/TinyLlama-1.1B-Chat-v1.0:  15%|█▌        | 3/20 [00:16<01:34,  5.53s/it]TinyLlama/TinyLlama-1.1B-Chat-v1.0:  20%|██        | 4/20 [00:22<01:28,  5.54s/it]TinyLlama/TinyLlama-1.1B-Chat-v1.0:  25%|██▌       | 5/20 [00:27<01:22,  5.48s/it]TinyLlama/TinyLlama-1.1B-Chat-v1.0:  30%|███       | 6/20 [00:33<01:16,  5.49s/it]TinyLlama/TinyLlama-1.1B-Chat-v1.0:  35%|███▌      | 7/20 [00:38<01:11,  5.50s/it]TinyLlama/TinyLlama-1.1B-Chat-v1.0:  40%|████      | 8/20 [00:44<01:05,  5.47s/it]TinyLlama/TinyLlama-1.1B-Chat-v1.0:  45%|████▌     | 9/20 [00:49<00:59,  5.44s/it]TinyLlama/TinyLlama-1.1B-Chat-v1.0:  50%|█████     | 10/20 [00:55<00:54,  5.47s/it]TinyLlama/TinyLlama-1.1B-Chat-v1.0:  55%|█████▌    | 11/20 [01:00<00:49,  5.49s/it]TinyLlama/TinyLlama-1.1B-Chat-v1.0:  60%|██████    | 12/20 [01:06<00:44,  5.53s/it]TinyLlama/TinyLlama-1.1B-Chat-v1.0:  65%|██████▌   | 13/20 [01:11<00:38,  5.49s/it]TinyLlama/TinyLlama-1.1B-Chat-v1.0:  70%|███████   | 14/20 [01:16<00:32,  5.47s/it]TinyLlama/TinyLlama-1.1B-Chat-v1.0:  75%|███████▌  | 15/20 [01:22<00:27,  5.50s/it]TinyLlama/TinyLlama-1.1B-Chat-v1.0:  80%|████████  | 16/20 [01:28<00:22,  5.52s/it]TinyLlama/TinyLlama-1.1B-Chat-v1.0:  85%|████████▌ | 17/20 [01:33<00:16,  5.58s/it]TinyLlama/TinyLlama-1.1B-Chat-v1.0:  90%|█████████ | 18/20 [01:39<00:11,  5.53s/it]TinyLlama/TinyLlama-1.1B-Chat-v1.0:  95%|█████████▌| 19/20 [01:44<00:05,  5.55s/it]TinyLlama/TinyLlama-1.1B-Chat-v1.0: 100%|██████████| 20/20 [01:50<00:00,  5.56s/it]TinyLlama/TinyLlama-1.1B-Chat-v1.0: 100%|██████████| 20/20 [01:50<00:00,  5.52s/it]
judge:   0%|          | 0/20 [00:00<?, ?it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.
The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
judge:   5%|▌         | 1/20 [00:12<04:06, 12.95s/it]judge:  10%|█         | 2/20 [00:25<03:52, 12.93s/it]judge:  15%|█▌        | 3/20 [00:38<03:39, 12.93s/it]judge:  20%|██        | 4/20 [00:52<03:29, 13.10s/it]judge:  25%|██▌       | 5/20 [01:05<03:16, 13.09s/it]judge:  30%|███       | 6/20 [01:18<03:02, 13.04s/it]judge:  35%|███▌      | 7/20 [01:32<02:54, 13.40s/it]judge:  40%|████      | 8/20 [01:46<02:42, 13.57s/it]judge:  45%|████▌     | 9/20 [01:59<02:27, 13.37s/it]judge:  50%|█████     | 10/20 [02:12<02:14, 13.48s/it]judge:  55%|█████▌    | 11/20 [02:26<02:01, 13.55s/it]judge:  60%|██████    | 12/20 [02:39<01:47, 13.46s/it]judge:  65%|██████▌   | 13/20 [02:53<01:33, 13.40s/it]judge:  70%|███████   | 14/20 [03:06<01:20, 13.36s/it]judge:  75%|███████▌  | 15/20 [03:19<01:06, 13.33s/it]judge:  80%|████████  | 16/20 [03:32<00:53, 13.31s/it]judge:  85%|████████▌ | 17/20 [03:46<00:39, 13.29s/it]judge:  90%|█████████ | 18/20 [03:59<00:26, 13.28s/it]judge:  95%|█████████▌| 19/20 [04:12<00:13, 13.27s/it]judge: 100%|██████████| 20/20 [04:25<00:00, 13.28s/it]judge: 100%|██████████| 20/20 [04:25<00:00, 13.30s/it]
`torch_dtype` is deprecated! Use `dtype` instead!
/mnt/vstor/courses/csds447/kvl16/project/csds447-health-qa-safety/venv/lib/python3.12/site-packages/peft/peft_model.py:598: UserWarning: Found missing adapter keys while loading the checkpoint: ['base_model.model.biogpt.layers.0.self_attn.v_proj.lora_A.default.weight', 'base_model.model.biogpt.layers.0.self_attn.v_proj.lora_B.default.weight', 'base_model.model.biogpt.layers.0.self_attn.q_proj.lora_A.default.weight', 'base_model.model.biogpt.layers.0.self_attn.q_proj.lora_B.default.weight', 'base_model.model.biogpt.layers.1.self_attn.v_proj.lora_A.default.weight', 'base_model.model.biogpt.layers.1.self_attn.v_proj.lora_B.default.weight', 'base_model.model.biogpt.layers.1.self_attn.q_proj.lora_A.default.weight', 'base_model.model.biogpt.layers.1.self_attn.q_proj.lora_B.default.weight', 'base_model.model.biogpt.layers.2.self_attn.v_proj.lora_A.default.weight', 'base_model.model.biogpt.layers.2.self_attn.v_proj.lora_B.default.weight', 'base_model.model.biogpt.layers.2.self_attn.q_proj.lora_A.default.weight', 'base_model.model.biogpt.layers.2.self_attn.q_proj.lora_B.default.weight', 'base_model.model.biogpt.layers.3.self_attn.v_proj.lora_A.default.weight', 'base_model.model.biogpt.layers.3.self_attn.v_proj.lora_B.default.weight', 'base_model.model.biogpt.layers.3.self_attn.q_proj.lora_A.default.weight', 'base_model.model.biogpt.layers.3.self_attn.q_proj.lora_B.default.weight', 'base_model.model.biogpt.layers.4.self_attn.v_proj.lora_A.default.weight', 'base_model.model.biogpt.layers.4.self_attn.v_proj.lora_B.default.weight', 'base_model.model.biogpt.layers.4.self_attn.q_proj.lora_A.default.weight', 'base_model.model.biogpt.layers.4.self_attn.q_proj.lora_B.default.weight', 'base_model.model.biogpt.layers.5.self_attn.v_proj.lora_A.default.weight', 'base_model.model.biogpt.layers.5.self_attn.v_proj.lora_B.default.weight', 'base_model.model.biogpt.layers.5.self_attn.q_proj.lora_A.default.weight', 'base_model.model.biogpt.layers.5.self_attn.q_proj.lora_B.default.weight', 'base_model.model.biogpt.layers.6.self_attn.v_proj.lora_A.default.weight', 'base_model.model.biogpt.layers.6.self_attn.v_proj.lora_B.default.weight', 'base_model.model.biogpt.layers.6.self_attn.q_proj.lora_A.default.weight', 'base_model.model.biogpt.layers.6.self_attn.q_proj.lora_B.default.weight', 'base_model.model.biogpt.layers.7.self_attn.v_proj.lora_A.default.weight', 'base_model.model.biogpt.layers.7.self_attn.v_proj.lora_B.default.weight', 'base_model.model.biogpt.layers.7.self_attn.q_proj.lora_A.default.weight', 'base_model.model.biogpt.layers.7.self_attn.q_proj.lora_B.default.weight', 'base_model.model.biogpt.layers.8.self_attn.v_proj.lora_A.default.weight', 'base_model.model.biogpt.layers.8.self_attn.v_proj.lora_B.default.weight', 'base_model.model.biogpt.layers.8.self_attn.q_proj.lora_A.default.weight', 'base_model.model.biogpt.layers.8.self_attn.q_proj.lora_B.default.weight', 'base_model.model.biogpt.layers.9.self_attn.v_proj.lora_A.default.weight', 'base_model.model.biogpt.layers.9.self_attn.v_proj.lora_B.default.weight', 'base_model.model.biogpt.layers.9.self_attn.q_proj.lora_A.default.weight', 'base_model.model.biogpt.layers.9.self_attn.q_proj.lora_B.default.weight', 'base_model.model.biogpt.layers.10.self_attn.v_proj.lora_A.default.weight', 'base_model.model.biogpt.layers.10.self_attn.v_proj.lora_B.default.weight', 'base_model.model.biogpt.layers.10.self_attn.q_proj.lora_A.default.weight', 'base_model.model.biogpt.layers.10.self_attn.q_proj.lora_B.default.weight', 'base_model.model.biogpt.layers.11.self_attn.v_proj.lora_A.default.weight', 'base_model.model.biogpt.layers.11.self_attn.v_proj.lora_B.default.weight', 'base_model.model.biogpt.layers.11.self_attn.q_proj.lora_A.default.weight', 'base_model.model.biogpt.layers.11.self_attn.q_proj.lora_B.default.weight', 'base_model.model.biogpt.layers.12.self_attn.v_proj.lora_A.default.weight', 'base_model.model.biogpt.layers.12.self_attn.v_proj.lora_B.default.weight', 'base_model.model.biogpt.layers.12.self_attn.q_proj.lora_A.default.weight', 'base_model.model.biogpt.layers.12.self_attn.q_proj.lora_B.default.weight', 'base_model.model.biogpt.layers.13.self_attn.v_proj.lora_A.default.weight', 'base_model.model.biogpt.layers.13.self_attn.v_proj.lora_B.default.weight', 'base_model.model.biogpt.layers.13.self_attn.q_proj.lora_A.default.weight', 'base_model.model.biogpt.layers.13.self_attn.q_proj.lora_B.default.weight', 'base_model.model.biogpt.layers.14.self_attn.v_proj.lora_A.default.weight', 'base_model.model.biogpt.layers.14.self_attn.v_proj.lora_B.default.weight', 'base_model.model.biogpt.layers.14.self_attn.q_proj.lora_A.default.weight', 'base_model.model.biogpt.layers.14.self_attn.q_proj.lora_B.default.weight', 'base_model.model.biogpt.layers.15.self_attn.v_proj.lora_A.default.weight', 'base_model.model.biogpt.layers.15.self_attn.v_proj.lora_B.default.weight', 'base_model.model.biogpt.layers.15.self_attn.q_proj.lora_A.default.weight', 'base_model.model.biogpt.layers.15.self_attn.q_proj.lora_B.default.weight', 'base_model.model.biogpt.layers.16.self_attn.v_proj.lora_A.default.weight', 'base_model.model.biogpt.layers.16.self_attn.v_proj.lora_B.default.weight', 'base_model.model.biogpt.layers.16.self_attn.q_proj.lora_A.default.weight', 'base_model.model.biogpt.layers.16.self_attn.q_proj.lora_B.default.weight', 'base_model.model.biogpt.layers.17.self_attn.v_proj.lora_A.default.weight', 'base_model.model.biogpt.layers.17.self_attn.v_proj.lora_B.default.weight', 'base_model.model.biogpt.layers.17.self_attn.q_proj.lora_A.default.weight', 'base_model.model.biogpt.layers.17.self_attn.q_proj.lora_B.default.weight', 'base_model.model.biogpt.layers.18.self_attn.v_proj.lora_A.default.weight', 'base_model.model.biogpt.layers.18.self_attn.v_proj.lora_B.default.weight', 'base_model.model.biogpt.layers.18.self_attn.q_proj.lora_A.default.weight', 'base_model.model.biogpt.layers.18.self_attn.q_proj.lora_B.default.weight', 'base_model.model.biogpt.layers.19.self_attn.v_proj.lora_A.default.weight', 'base_model.model.biogpt.layers.19.self_attn.v_proj.lora_B.default.weight', 'base_model.model.biogpt.layers.19.self_attn.q_proj.lora_A.default.weight', 'base_model.model.biogpt.layers.19.self_attn.q_proj.lora_B.default.weight', 'base_model.model.biogpt.layers.20.self_attn.v_proj.lora_A.default.weight', 'base_model.model.biogpt.layers.20.self_attn.v_proj.lora_B.default.weight', 'base_model.model.biogpt.layers.20.self_attn.q_proj.lora_A.default.weight', 'base_model.model.biogpt.layers.20.self_attn.q_proj.lora_B.default.weight', 'base_model.model.biogpt.layers.21.self_attn.v_proj.lora_A.default.weight', 'base_model.model.biogpt.layers.21.self_attn.v_proj.lora_B.default.weight', 'base_model.model.biogpt.layers.21.self_attn.q_proj.lora_A.default.weight', 'base_model.model.biogpt.layers.21.self_attn.q_proj.lora_B.default.weight', 'base_model.model.biogpt.layers.22.self_attn.v_proj.lora_A.default.weight', 'base_model.model.biogpt.layers.22.self_attn.v_proj.lora_B.default.weight', 'base_model.model.biogpt.layers.22.self_attn.q_proj.lora_A.default.weight', 'base_model.model.biogpt.layers.22.self_attn.q_proj.lora_B.default.weight', 'base_model.model.biogpt.layers.23.self_attn.v_proj.lora_A.default.weight', 'base_model.model.biogpt.layers.23.self_attn.v_proj.lora_B.default.weight', 'base_model.model.biogpt.layers.23.self_attn.q_proj.lora_A.default.weight', 'base_model.model.biogpt.layers.23.self_attn.q_proj.lora_B.default.weight', 'base_model.model.biogpt.layers.24.self_attn.v_proj.lora_A.default.weight', 'base_model.model.biogpt.layers.24.self_attn.v_proj.lora_B.default.weight', 'base_model.model.biogpt.layers.24.self_attn.q_proj.lora_A.default.weight', 'base_model.model.biogpt.layers.24.self_attn.q_proj.lora_B.default.weight', 'base_model.model.biogpt.layers.25.self_attn.v_proj.lora_A.default.weight', 'base_model.model.biogpt.layers.25.self_attn.v_proj.lora_B.default.weight', 'base_model.model.biogpt.layers.25.self_attn.q_proj.lora_A.default.weight', 'base_model.model.biogpt.layers.25.self_attn.q_proj.lora_B.default.weight', 'base_model.model.biogpt.layers.26.self_attn.v_proj.lora_A.default.weight', 'base_model.model.biogpt.layers.26.self_attn.v_proj.lora_B.default.weight', 'base_model.model.biogpt.layers.26.self_attn.q_proj.lora_A.default.weight', 'base_model.model.biogpt.layers.26.self_attn.q_proj.lora_B.default.weight', 'base_model.model.biogpt.layers.27.self_attn.v_proj.lora_A.default.weight', 'base_model.model.biogpt.layers.27.self_attn.v_proj.lora_B.default.weight', 'base_model.model.biogpt.layers.27.self_attn.q_proj.lora_A.default.weight', 'base_model.model.biogpt.layers.27.self_attn.q_proj.lora_B.default.weight', 'base_model.model.biogpt.layers.28.self_attn.v_proj.lora_A.default.weight', 'base_model.model.biogpt.layers.28.self_attn.v_proj.lora_B.default.weight', 'base_model.model.biogpt.layers.28.self_attn.q_proj.lora_A.default.weight', 'base_model.model.biogpt.layers.28.self_attn.q_proj.lora_B.default.weight', 'base_model.model.biogpt.layers.29.self_attn.v_proj.lora_A.default.weight', 'base_model.model.biogpt.layers.29.self_attn.v_proj.lora_B.default.weight', 'base_model.model.biogpt.layers.29.self_attn.q_proj.lora_A.default.weight', 'base_model.model.biogpt.layers.29.self_attn.q_proj.lora_B.default.weight', 'base_model.model.biogpt.layers.30.self_attn.v_proj.lora_A.default.weight', 'base_model.model.biogpt.layers.30.self_attn.v_proj.lora_B.default.weight', 'base_model.model.biogpt.layers.30.self_attn.q_proj.lora_A.default.weight', 'base_model.model.biogpt.layers.30.self_attn.q_proj.lora_B.default.weight', 'base_model.model.biogpt.layers.31.self_attn.v_proj.lora_A.default.weight', 'base_model.model.biogpt.layers.31.self_attn.v_proj.lora_B.default.weight', 'base_model.model.biogpt.layers.31.self_attn.q_proj.lora_A.default.weight', 'base_model.model.biogpt.layers.31.self_attn.q_proj.lora_B.default.weight', 'base_model.model.biogpt.layers.32.self_attn.v_proj.lora_A.default.weight', 'base_model.model.biogpt.layers.32.self_attn.v_proj.lora_B.default.weight', 'base_model.model.biogpt.layers.32.self_attn.q_proj.lora_A.default.weight', 'base_model.model.biogpt.layers.32.self_attn.q_proj.lora_B.default.weight', 'base_model.model.biogpt.layers.33.self_attn.v_proj.lora_A.default.weight', 'base_model.model.biogpt.layers.33.self_attn.v_proj.lora_B.default.weight', 'base_model.model.biogpt.layers.33.self_attn.q_proj.lora_A.default.weight', 'base_model.model.biogpt.layers.33.self_attn.q_proj.lora_B.default.weight', 'base_model.model.biogpt.layers.34.self_attn.v_proj.lora_A.default.weight', 'base_model.model.biogpt.layers.34.self_attn.v_proj.lora_B.default.weight', 'base_model.model.biogpt.layers.34.self_attn.q_proj.lora_A.default.weight', 'base_model.model.biogpt.layers.34.self_attn.q_proj.lora_B.default.weight', 'base_model.model.biogpt.layers.35.self_attn.v_proj.lora_A.default.weight', 'base_model.model.biogpt.layers.35.self_attn.v_proj.lora_B.default.weight', 'base_model.model.biogpt.layers.35.self_attn.q_proj.lora_A.default.weight', 'base_model.model.biogpt.layers.35.self_attn.q_proj.lora_B.default.weight', 'base_model.model.biogpt.layers.36.self_attn.v_proj.lora_A.default.weight', 'base_model.model.biogpt.layers.36.self_attn.v_proj.lora_B.default.weight', 'base_model.model.biogpt.layers.36.self_attn.q_proj.lora_A.default.weight', 'base_model.model.biogpt.layers.36.self_attn.q_proj.lora_B.default.weight', 'base_model.model.biogpt.layers.37.self_attn.v_proj.lora_A.default.weight', 'base_model.model.biogpt.layers.37.self_attn.v_proj.lora_B.default.weight', 'base_model.model.biogpt.layers.37.self_attn.q_proj.lora_A.default.weight', 'base_model.model.biogpt.layers.37.self_attn.q_proj.lora_B.default.weight', 'base_model.model.biogpt.layers.38.self_attn.v_proj.lora_A.default.weight', 'base_model.model.biogpt.layers.38.self_attn.v_proj.lora_B.default.weight', 'base_model.model.biogpt.layers.38.self_attn.q_proj.lora_A.default.weight', 'base_model.model.biogpt.layers.38.self_attn.q_proj.lora_B.default.weight', 'base_model.model.biogpt.layers.39.self_attn.v_proj.lora_A.default.weight', 'base_model.model.biogpt.layers.39.self_attn.v_proj.lora_B.default.weight', 'base_model.model.biogpt.layers.39.self_attn.q_proj.lora_A.default.weight', 'base_model.model.biogpt.layers.39.self_attn.q_proj.lora_B.default.weight', 'base_model.model.biogpt.layers.40.self_attn.v_proj.lora_A.default.weight', 'base_model.model.biogpt.layers.40.self_attn.v_proj.lora_B.default.weight', 'base_model.model.biogpt.layers.40.self_attn.q_proj.lora_A.default.weight', 'base_model.model.biogpt.layers.40.self_attn.q_proj.lora_B.default.weight', 'base_model.model.biogpt.layers.41.self_attn.v_proj.lora_A.default.weight', 'base_model.model.biogpt.layers.41.self_attn.v_proj.lora_B.default.weight', 'base_model.model.biogpt.layers.41.self_attn.q_proj.lora_A.default.weight', 'base_model.model.biogpt.layers.41.self_attn.q_proj.lora_B.default.weight', 'base_model.model.biogpt.layers.42.self_attn.v_proj.lora_A.default.weight', 'base_model.model.biogpt.layers.42.self_attn.v_proj.lora_B.default.weight', 'base_model.model.biogpt.layers.42.self_attn.q_proj.lora_A.default.weight', 'base_model.model.biogpt.layers.42.self_attn.q_proj.lora_B.default.weight', 'base_model.model.biogpt.layers.43.self_attn.v_proj.lora_A.default.weight', 'base_model.model.biogpt.layers.43.self_attn.v_proj.lora_B.default.weight', 'base_model.model.biogpt.layers.43.self_attn.q_proj.lora_A.default.weight', 'base_model.model.biogpt.layers.43.self_attn.q_proj.lora_B.default.weight', 'base_model.model.biogpt.layers.44.self_attn.v_proj.lora_A.default.weight', 'base_model.model.biogpt.layers.44.self_attn.v_proj.lora_B.default.weight', 'base_model.model.biogpt.layers.44.self_attn.q_proj.lora_A.default.weight', 'base_model.model.biogpt.layers.44.self_attn.q_proj.lora_B.default.weight', 'base_model.model.biogpt.layers.45.self_attn.v_proj.lora_A.default.weight', 'base_model.model.biogpt.layers.45.self_attn.v_proj.lora_B.default.weight', 'base_model.model.biogpt.layers.45.self_attn.q_proj.lora_A.default.weight', 'base_model.model.biogpt.layers.45.self_attn.q_proj.lora_B.default.weight', 'base_model.model.biogpt.layers.46.self_attn.v_proj.lora_A.default.weight', 'base_model.model.biogpt.layers.46.self_attn.v_proj.lora_B.default.weight', 'base_model.model.biogpt.layers.46.self_attn.q_proj.lora_A.default.weight', 'base_model.model.biogpt.layers.46.self_attn.q_proj.lora_B.default.weight', 'base_model.model.biogpt.layers.47.self_attn.v_proj.lora_A.default.weight', 'base_model.model.biogpt.layers.47.self_attn.v_proj.lora_B.default.weight', 'base_model.model.biogpt.layers.47.self_attn.q_proj.lora_A.default.weight', 'base_model.model.biogpt.layers.47.self_attn.q_proj.lora_B.default.weight'].
  warnings.warn(warn_message)
microsoft/BioGPT-Large:   0%|          | 0/20 [00:00<?, ?it/s]microsoft/BioGPT-Large:   5%|▌         | 1/20 [00:01<00:20,  1.10s/it]microsoft/BioGPT-Large:  10%|█         | 2/20 [00:01<00:15,  1.14it/s]microsoft/BioGPT-Large:  15%|█▌        | 3/20 [00:02<00:13,  1.23it/s]microsoft/BioGPT-Large:  20%|██        | 4/20 [00:03<00:12,  1.29it/s]microsoft/BioGPT-Large:  25%|██▌       | 5/20 [00:04<00:11,  1.31it/s]microsoft/BioGPT-Large:  30%|███       | 6/20 [00:04<00:10,  1.32it/s]microsoft/BioGPT-Large:  35%|███▌      | 7/20 [00:05<00:09,  1.34it/s]microsoft/BioGPT-Large:  40%|████      | 8/20 [00:06<00:08,  1.35it/s]microsoft/BioGPT-Large:  45%|████▌     | 9/20 [00:06<00:08,  1.35it/s]microsoft/BioGPT-Large:  50%|█████     | 10/20 [00:07<00:07,  1.36it/s]microsoft/BioGPT-Large:  55%|█████▌    | 11/20 [00:08<00:06,  1.37it/s]microsoft/BioGPT-Large:  60%|██████    | 12/20 [00:09<00:05,  1.36it/s]microsoft/BioGPT-Large:  65%|██████▌   | 13/20 [00:09<00:05,  1.37it/s]microsoft/BioGPT-Large:  70%|███████   | 14/20 [00:10<00:04,  1.37it/s]microsoft/BioGPT-Large:  75%|███████▌  | 15/20 [00:11<00:03,  1.36it/s]microsoft/BioGPT-Large:  80%|████████  | 16/20 [00:12<00:02,  1.37it/s]microsoft/BioGPT-Large:  85%|████████▌ | 17/20 [00:12<00:02,  1.37it/s]microsoft/BioGPT-Large:  90%|█████████ | 18/20 [00:13<00:01,  1.36it/s]microsoft/BioGPT-Large:  95%|█████████▌| 19/20 [00:14<00:00,  1.36it/s]microsoft/BioGPT-Large: 100%|██████████| 20/20 [00:14<00:00,  1.36it/s]microsoft/BioGPT-Large: 100%|██████████| 20/20 [00:14<00:00,  1.33it/s]
judge:   0%|          | 0/20 [00:00<?, ?it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.
The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
judge:   5%|▌         | 1/20 [00:12<04:06, 12.99s/it]judge:  10%|█         | 2/20 [00:25<03:53, 12.96s/it]judge:  15%|█▌        | 3/20 [00:38<03:39, 12.93s/it]judge:  20%|██        | 4/20 [00:51<03:26, 12.90s/it]judge:  25%|██▌       | 5/20 [01:04<03:13, 12.91s/it]judge:  30%|███       | 6/20 [01:17<03:00, 12.91s/it]judge:  35%|███▌      | 7/20 [01:30<02:47, 12.91s/it]judge:  40%|████      | 8/20 [01:43<02:34, 12.91s/it]judge:  45%|████▌     | 9/20 [01:56<02:22, 12.91s/it]judge:  50%|█████     | 10/20 [02:09<02:08, 12.90s/it]judge:  55%|█████▌    | 11/20 [02:21<01:56, 12.89s/it]judge:  60%|██████    | 12/20 [02:34<01:43, 12.90s/it]judge:  65%|██████▌   | 13/20 [02:47<01:30, 12.89s/it]judge:  70%|███████   | 14/20 [03:00<01:17, 12.89s/it]judge:  75%|███████▌  | 15/20 [03:13<01:04, 12.89s/it]judge:  80%|████████  | 16/20 [03:26<00:51, 12.89s/it]judge:  85%|████████▌ | 17/20 [03:39<00:38, 12.90s/it]judge:  90%|█████████ | 18/20 [03:52<00:25, 12.89s/it]judge:  95%|█████████▌| 19/20 [04:05<00:12, 12.92s/it]judge: 100%|██████████| 20/20 [04:18<00:00, 12.93s/it]judge: 100%|██████████| 20/20 [04:18<00:00, 12.91s/it]
